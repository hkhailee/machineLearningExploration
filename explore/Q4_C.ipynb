{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Q4-C.ipynb","provenance":[],"authorship_tag":"ABX9TyO35wE+2pMWxFZ7SWq/nXKo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"D9CWol4THZB-"},"source":["# Question 4 (20 pts)--COMPLETE\n","Compare the technique in 2 with the coefficients (W) of the logistic regression by\n","discussing the results. (scikit)"]},{"cell_type":"code","metadata":{"id":"z-yspnRxHbis","executionInfo":{"status":"ok","timestamp":1620001260609,"user_tz":420,"elapsed":818,"user":{"displayName":"Hailee K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-K-gnA0SyJcEz2RHEd55BjXelge052dstnK98aA=s64","userId":"07223577005008820598"}}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import time\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.datasets import *\n","from sklearn.metrics import classification_report\n","from sklearn.preprocessing import StandardScaler"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"CIVTXbwkEKp2","executionInfo":{"status":"ok","timestamp":1620001260610,"user_tz":420,"elapsed":814,"user":{"displayName":"Hailee K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-K-gnA0SyJcEz2RHEd55BjXelge052dstnK98aA=s64","userId":"07223577005008820598"}}},"source":["# load sample data \n","X, y = load_wine(return_X_y= True)\n","scaled = StandardScaler()\n","X = scaled.fit_transform(X)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"aiAlMM3Di6f3","executionInfo":{"status":"ok","timestamp":1620001260610,"user_tz":420,"elapsed":810,"user":{"displayName":"Hailee K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-K-gnA0SyJcEz2RHEd55BjXelge052dstnK98aA=s64","userId":"07223577005008820598"}}},"source":["wine = load_wine()"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"OfiFS-xAEcqt","executionInfo":{"status":"ok","timestamp":1620001260612,"user_tz":420,"elapsed":809,"user":{"displayName":"Hailee K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-K-gnA0SyJcEz2RHEd55BjXelge052dstnK98aA=s64","userId":"07223577005008820598"}}},"source":["X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, stratify=y, random_state=42)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"0GPeUunLEQ3v","executionInfo":{"status":"ok","timestamp":1620001260613,"user_tz":420,"elapsed":806,"user":{"displayName":"Hailee K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-K-gnA0SyJcEz2RHEd55BjXelge052dstnK98aA=s64","userId":"07223577005008820598"}}},"source":["clf = LogisticRegression(random_state=0, max_iter=5000).fit(X_train, y_train)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432},"id":"AVVjY3VTijyn","executionInfo":{"status":"ok","timestamp":1620001260613,"user_tz":420,"elapsed":802,"user":{"displayName":"Hailee K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-K-gnA0SyJcEz2RHEd55BjXelge052dstnK98aA=s64","userId":"07223577005008820598"}},"outputId":"0fde8dd4-ef18-4d62-a6f0-86662b9a2b23"},"source":["pd.DataFrame({\"Feature\": wine.feature_names,\"Coefficients\":clf.coef_[0]})"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Feature</th>\n","      <th>Coefficients</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>alcohol</td>\n","      <td>0.726408</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>malic_acid</td>\n","      <td>0.167155</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ash</td>\n","      <td>0.477955</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>alcalinity_of_ash</td>\n","      <td>-0.817347</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>magnesium</td>\n","      <td>0.079883</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>total_phenols</td>\n","      <td>0.234553</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>flavanoids</td>\n","      <td>0.697365</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>nonflavanoid_phenols</td>\n","      <td>-0.114432</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>proanthocyanins</td>\n","      <td>0.145667</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>color_intensity</td>\n","      <td>0.193179</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>hue</td>\n","      <td>0.096865</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>od280/od315_of_diluted_wines</td>\n","      <td>0.658948</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>proline</td>\n","      <td>0.923848</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                         Feature  Coefficients\n","0                        alcohol      0.726408\n","1                     malic_acid      0.167155\n","2                            ash      0.477955\n","3              alcalinity_of_ash     -0.817347\n","4                      magnesium      0.079883\n","5                  total_phenols      0.234553\n","6                     flavanoids      0.697365\n","7           nonflavanoid_phenols     -0.114432\n","8                proanthocyanins      0.145667\n","9                color_intensity      0.193179\n","10                           hue      0.096865\n","11  od280/od315_of_diluted_wines      0.658948\n","12                       proline      0.923848"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"R8FC0dPAjUbR"},"source":["From the technique in question 2 we were able to deduce that the most influental features were flavanoids, color_intensity, and proline. Using logistic regression, proline is still a top influencing feature along with alchol, and flavanoids. Slightly different than the plot forest technique. What is strange is how high color_intesity scaled in question 2, it was the highest ranking, here its appearing to be a very low ball feature.\n"]},{"cell_type":"code","metadata":{"id":"vMSByjNuEkVY","executionInfo":{"status":"ok","timestamp":1620001260613,"user_tz":420,"elapsed":797,"user":{"displayName":"Hailee K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-K-gnA0SyJcEz2RHEd55BjXelge052dstnK98aA=s64","userId":"07223577005008820598"}}},"source":["\n","x = load_wine()\n","df = pd.DataFrame(x.data, columns = x.feature_names)\n","df = df.drop(columns = ['malic_acid','color_intensity', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'nonflavanoid_phenols', 'proanthocyanins', 'hue', 'od280/od315_of_diluted_wines'])\n","scaled = StandardScaler()\n","X_scale = scaled.fit_transform(df)\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_scale, y, stratify=y, random_state=42)\n","\n","clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n","y_preds = clf.predict(X_test[:, :])"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MT5t17ciF5md","executionInfo":{"status":"ok","timestamp":1620001260614,"user_tz":420,"elapsed":794,"user":{"displayName":"Hailee K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-K-gnA0SyJcEz2RHEd55BjXelge052dstnK98aA=s64","userId":"07223577005008820598"}},"outputId":"0d758ac8-d621-453e-d47e-5b698704f44c"},"source":["target_names = ['class 0', 'class 1', 'class 2']\n","print(classification_report(y_test, y_preds, target_names=target_names))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     class 0       1.00      1.00      1.00        15\n","     class 1       1.00      0.94      0.97        18\n","     class 2       0.92      1.00      0.96        12\n","\n","    accuracy                           0.98        45\n","   macro avg       0.97      0.98      0.98        45\n","weighted avg       0.98      0.98      0.98        45\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EMi-FNi8l8hE","executionInfo":{"status":"ok","timestamp":1620001260747,"user_tz":420,"elapsed":923,"user":{"displayName":"Hailee K","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-K-gnA0SyJcEz2RHEd55BjXelge052dstnK98aA=s64","userId":"07223577005008820598"}},"outputId":"aca66d4e-be35-419d-8f24-ec19e5a63493"},"source":["clf.score(X_test, y_test)"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9777777777777777"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"GhiA8dhRlszZ"},"source":["Logistic regression acting alone without the forest plot methodology, actually ended up scoring higher after modifications than in question 2. After making alterations with the found core features in question 2, score was at 0.9333. Making modifications listening to logistic regression only, the score is at 0.9777, quite a bit of an increase. "]}]}